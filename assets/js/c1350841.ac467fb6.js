(self.webpackChunkactivejdocs=self.webpackChunkactivejdocs||[]).push([[583],{77618:function(e,t,a){"use strict";var n=a(95318).default;t.Z=void 0;var r=n(a(67294)),i=n(a(39962)),o=function(e){var t=e.url,a=e.text,n=e.isInline,o=void 0===n||n,l=e.children,d=(0,i.default)().siteConfig;return r.default.createElement("a",{style:o?{}:{display:"block",marginBottom:"16px"},href:d.customFields.githubUrl+"/"+d.customFields.githubBranch+t,target:"_blank"},a||l)};t.Z=o},14304:function(e,t,a){"use strict";var n=a(95318).default,r=a(20862).default;t.Z=void 0;var i=r(a(67294)),o=n(a(21140));o.default.initialize({startOnLoad:!0});var l=function(e){var t=e.chart;return(0,i.useEffect)((function(){o.default.contentLoaded()}),[]),i.default.createElement("div",{className:"mermaid"},t)};t.Z=l},77815:function(e,t,a){"use strict";var n=a(95318).default;t.Z=void 0;n(a(67294));var r=n(a(39962)),i=function(e){var t=e.name,a=(0,r.default)().siteConfig;if(!t)throw new Error("Variable name is required");if(void 0===a.customFields[t])throw new Error("Variable "+t+" not exist");return a.customFields[t]};t.Z=i},82397:function(e,t,a){"use strict";a.r(t),a.d(t,{frontMatter:function(){return c},metadata:function(){return m},toc:function(){return u},default:function(){return h}});var n=a(22122),r=a(19756),i=(a(67294),a(3905)),o=a(14304),l=a(77815),d=a(77618),s=["components"],c={title:"ActiveJ | Dataflow, distributed stream-based batch processing engine",description:"Dataflow is an efficient tool for big data distributed applications. It offers a high-performance stream-based batch processing engine for working with partitions",keywords:["java","dataflow","big data","streams","batch processing"],sidebar_position:7},m={unversionedId:"async-io/dataflow",id:"async-io/dataflow",isDocsHomePage:!1,title:"Dataflow",description:"Dataflow is an efficient tool for big data distributed applications. It offers a high-performance stream-based batch processing engine for working with partitions",source:"@site/docs/async-io/dataflow.mdx",sourceDirName:"async-io",slug:"/async-io/dataflow",permalink:"/async-io/dataflow",version:"current",sidebarPosition:7,frontMatter:{title:"ActiveJ | Dataflow, distributed stream-based batch processing engine",description:"Dataflow is an efficient tool for big data distributed applications. It offers a high-performance stream-based batch processing engine for working with partitions",keywords:["java","dataflow","big data","streams","batch processing"],sidebar_position:7},sidebar:"docs",previous:{title:"Net",permalink:"/async-io/net"},next:{title:"Launcher",permalink:"/boot/launcher"}},u=[{value:"Example",id:"example",children:[{value:"1. Create a Dataflow Server Launcher",id:"1-create-a-dataflow-server-launcher",children:[]},{value:"2. Create a Dataflow Client Launcher with a task",id:"2-create-a-dataflow-client-launcher-with-a-task",children:[]},{value:"Testing",id:"testing",children:[]}]}],p={toc:u};function h(e){var t=e.components,a=(0,r.default)(e,s);return(0,i.mdx)("wrapper",(0,n.default)({},p,a,{components:t,mdxType:"MDXLayout"}),(0,i.mdx)("p",null,"Dataflow is a distributed stream-based batch processing engine for big data applications.\nYou can create tasks on your client that will be executed on Dataflow servers with datasets. The task compiles into an\nexecution graph that will be executed on partitions."),(0,i.mdx)("h2",{id:"example"},"Example"),(0,i.mdx)("p",null,"In this example we will posts a simple Map-Reduce task to a cluster of Dataflow nodes."),(0,i.mdx)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.mdx)("div",{parentName:"div",className:"admonition-heading"},(0,i.mdx)("h5",{parentName:"div"},(0,i.mdx)("span",{parentName:"h5",className:"admonition-icon"},(0,i.mdx)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.mdx)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.mdx)("div",{parentName:"div",className:"admonition-content"},(0,i.mdx)("p",{parentName:"div"},"To run the examples, you need to clone ActiveJ from GitHub"),(0,i.mdx)("pre",{parentName:"div"},(0,i.mdx)("code",{parentName:"pre",className:"language-shell"},"git clone https://github.com/activej/activej\n")),(0,i.mdx)("p",{parentName:"div"},"And import it as a Maven project. Check out tag ",(0,i.mdx)("strong",{parentName:"p"},(0,i.mdx)(l.Z,{name:"currentVersion",mdxType:"Variable"})),". Before running the examples, build the project.\nThese examples are located at ",(0,i.mdx)("inlineCode",{parentName:"p"},"activej/examples/core/dataflow")))),(0,i.mdx)("h3",{id:"1-create-a-dataflow-server-launcher"},"1. Create a Dataflow Server Launcher"),(0,i.mdx)("p",null,'First, we need to launch two Dataflow servers. Each of them will have its own "items" dataset that contains 10K random words that can overlap.\nTo create a Dataflow server launcher we\'ll use pre-defined ',(0,i.mdx)(d.Z,{url:"/launchers/dataflow/src/main/java/io/activej/launchers/dataflow/DataflowServerLauncher.java",mdxType:"Githublink"},(0,i.mdx)("inlineCode",{parentName:"p"},"DataflowServerLauncher"))," class that extends ",(0,i.mdx)("a",{parentName:"p",href:"/boot/launcher"},(0,i.mdx)("inlineCode",{parentName:"a"},"Launcher"))," class."),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-java",metastring:"url=/examples/core/dataflow/src/main/java/DataflowServerLauncherExample.java tag=EXAMPLE",url:"/examples/core/dataflow/src/main/java/DataflowServerLauncherExample.java",tag:"EXAMPLE"},'public final class DataflowServerLauncherExample extends DataflowServerLauncher {\n\n  @Override\n  protected Module getOverrideModule() {\n    return ModuleBuilder.create()\n        .bind(codec(CreateStringCountFunction.class)).toInstance(ofObject(CreateStringCountFunction::new))\n        .bind(codec(ExtractStringFunction.class)).toInstance(ofObject(ExtractStringFunction::new))\n        .bind(codec(StringCountReducer.class)).toInstance(ofObject(StringCountReducer::new))\n\n        .bind(StreamSorterStorageFactory.class).toInstance(StreamMergeSorterStorageStub.FACTORY_STUB)\n\n        .bind(Config.class).toInstance(\n            Config.create()\n                .with("dataflow.server.listenAddresses", args.length > 0 ? args[0] : "9000")\n                .with("dataflow.secondaryBufferPath", Util.createTempDir("dataflow-server-secondary-storage")))\n        .build();\n  }\n\n  @Provides\n  @DatasetId("items")\n  List<String> words() {\n    String file = args.length > 1 ? args[1] : "words1.txt";\n    return new BufferedReader(new InputStreamReader(getClass().getResourceAsStream(file)))\n        .lines()\n        .filter(s -> !s.isEmpty())\n        .collect(toList());\n  }\n\n  public static void main(String[] args) throws Exception {\n    new DataflowServerLauncherExample().launch(args);\n  }\n}\n')),(0,i.mdx)("p",null,"First, override ",(0,i.mdx)("inlineCode",{parentName:"p"},"getOverrideModule")," method to create an abstract module with all the needed bindings: ",(0,i.mdx)(d.Z,{url:"/examples/core/dataflow/src/main/java/dto/CreateStringCountFunction.java",mdxType:"Githublink"},(0,i.mdx)("inlineCode",{parentName:"p"},"CreateStringCountFunction")),", ",(0,i.mdx)(d.Z,{url:"/examples/core/dataflow/src/main/java/dto/ExtractStringFunction.java",mdxType:"Githublink"},(0,i.mdx)("inlineCode",{parentName:"p"},"ExtractStringFunction")),", ",(0,i.mdx)(d.Z,{url:"/examples/core/dataflow/src/main/java/dto/StringCountReducer.java",mdxType:"Githublink"},(0,i.mdx)("inlineCode",{parentName:"p"},"StringCountReducer")),", ",(0,i.mdx)(d.Z,{url:"/extra/cloud-dataflow/src/main/java/io/activej/dataflow/node/NodeSort.java#L42",mdxType:"Githublink"},(0,i.mdx)("inlineCode",{parentName:"p"},"StreamSorterStorageFactory"))," and ",(0,i.mdx)("a",{parentName:"p",href:"/boot/config"},"Config"),".\nNext, we create ",(0,i.mdx)("em",{parentName:"p"},"words")," method to efficiently retrieve a list of Strings from the ",(0,i.mdx)("inlineCode",{parentName:"p"},".txt")," file."),(0,i.mdx)("p",null,"Finally, we define ",(0,i.mdx)("inlineCode",{parentName:"p"},"main")," method for starting our launcher."),(0,i.mdx)("p",null,(0,i.mdx)("strong",{parentName:"p"},(0,i.mdx)(d.Z,{url:"/examples/core/dataflow/src/main/java/DataflowServerLauncherExample.java",mdxType:"Githublink"},"See full example on GitHub"))),(0,i.mdx)("h3",{id:"2-create-a-dataflow-client-launcher-with-a-task"},"2. Create a Dataflow Client Launcher with a task"),(0,i.mdx)("p",null,"Let's now create a Dataflow client launcher. We'll make it by analogy with the server launcher. So we override ",(0,i.mdx)("inlineCode",{parentName:"p"},"getOverrideModule")," and provide the same required dependencies:"),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-java",metastring:"url=/examples/core/dataflow/src/main/java/DataflowClientLauncherExample.java tag=REGION_1",url:"/examples/core/dataflow/src/main/java/DataflowClientLauncherExample.java",tag:"REGION_1"},'public final class DataflowClientLauncherExample extends DataflowClientLauncher {\n  private static final String DEFAULT_PARTITION = "127.0.0.1:9000";\n\n  @Inject\n  DataflowClient client;\n\n  @Inject\n  DataflowGraph graph;\n\n  @Inject\n  Eventloop eventloop;\n\n  @Override\n  protected Module getOverrideModule() {\n    return ModuleBuilder.create()\n        .bind(codec(CreateStringCountFunction.class)).toInstance(ofObject(CreateStringCountFunction::new))\n        .bind(codec(ExtractStringFunction.class)).toInstance(ofObject(ExtractStringFunction::new))\n        .bind(codec(StringCountReducer.class)).toInstance(ofObject(StringCountReducer::new))\n\n        .bind(StreamSorterStorageFactory.class).toInstance(StreamMergeSorterStorageStub.FACTORY_STUB)\n\n        .bind(Config.class).toInstance(\n            Config.create()\n                .with("dataflow.secondaryBufferPath", Util.createTempDir("dataflow-client-secondary-storage"))\n                .with("dataflow.partitions", args.length == 0 ? DEFAULT_PARTITION : String.join(",", args)))\n        .build();\n  }\n')),(0,i.mdx)("p",null,"Now let's create a task for our Dataflow partitions. We'll define it in the overridden Launcher's main method ",(0,i.mdx)("inlineCode",{parentName:"p"},"run"),":"),(0,i.mdx)("pre",null,(0,i.mdx)("code",{parentName:"pre",className:"language-java",metastring:"url=/examples/core/dataflow/src/main/java/DataflowClientLauncherExample.java tag=REGION_2",url:"/examples/core/dataflow/src/main/java/DataflowClientLauncherExample.java",tag:"REGION_2"},'@Override\nprotected void run() throws InterruptedException {\n  eventloop.execute(() -> {\n    StringCountReducer reducer = new StringCountReducer();\n    ExtractStringFunction keyFunction = new ExtractStringFunction();\n\n    Dataset<String> items = datasetOfId("items", String.class);\n\n    Dataset<StringCount> mappedItems = map(items, new CreateStringCountFunction(), StringCount.class);\n\n    LocallySortedDataset<String, StringCount> locallySorted = localSort(mappedItems, String.class, keyFunction, naturalOrder());\n\n    LocallySortedDataset<String, StringCount> locallyReduced = localReduce(locallySorted, reducer.inputToAccumulator(), StringCount.class, keyFunction);\n\n    Dataset<StringCount> reducedItems = repartitionReduce(locallyReduced, reducer.accumulatorToOutput(), StringCount.class);\n\n    MergeCollector<String, StringCount> collector = new MergeCollector<>(reducedItems, client, keyFunction, naturalOrder(), false);\n\n    StreamSupplier<StringCount> resultSupplier = collector.compile(graph);\n\n    StreamConsumerToList<StringCount> resultConsumer = StreamConsumerToList.create();\n\n    System.out.println("\\n *** Dataset graph:\\n");\n    System.out.println(reducedItems.toGraphViz());\n    System.out.println("\\n *** Compiled nodes graph:\\n");\n    System.out.println(graph.toGraphViz());\n\n    graph.execute().both(resultSupplier.streamTo(resultConsumer))\n        .whenException(Throwable::printStackTrace)\n        .whenResult(() -> {\n          System.out.println("Top 100 words:");\n          resultConsumer.getList().stream().limit(100).forEach(System.out::println);\n        })\n        .whenComplete(this::shutdown);\n  });\n\n  awaitShutdown();\n}\n\npublic static void main(String[] args) throws Exception {\n  new DataflowClientLauncherExample().launch(args);\n}\n')),(0,i.mdx)("p",null,"This code does the following:"),(0,i.mdx)("ol",null,(0,i.mdx)("li",{parentName:"ol"},"Maps strings by creating ",(0,i.mdx)("inlineCode",{parentName:"li"},"('word', 1)")," pairs"),(0,i.mdx)("li",{parentName:"ol"},"Sorts the pairs in alphabetic order by the String value"),(0,i.mdx)("li",{parentName:"ol"},"Reduces the pairs by merging similar word pairs. For example, ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 1)")," and ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 1)")," will be reduced into ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 2)")),(0,i.mdx)("li",{parentName:"ol"},"Distributes the pairs according to a provided rule. For example, if ",(0,i.mdx)("strong",{parentName:"li"},"partition 1")," contains ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 2)"),", ",(0,i.mdx)("inlineCode",{parentName:"li"},"(dog, 2)")," and\n",(0,i.mdx)("strong",{parentName:"li"},"partition 2")," contains ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 3)"),", ",(0,i.mdx)("inlineCode",{parentName:"li"},"(dog, 1)")," the result of repartitioning might be ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 2)"),", ",(0,i.mdx)("inlineCode",{parentName:"li"},"(apple, 3)")," on ",(0,i.mdx)("strong",{parentName:"li"},"partition 1")," and\n",(0,i.mdx)("inlineCode",{parentName:"li"},"(dog, 2)"),", ",(0,i.mdx)("inlineCode",{parentName:"li"},"(dog, 1)")," on ",(0,i.mdx)("strong",{parentName:"li"},"partition 2"),"."),(0,i.mdx)("li",{parentName:"ol"},"Repeats ",(0,i.mdx)("strong",{parentName:"li"},"step 3"),". As a result of these steps, we receive a sorted and reduced dataset with unique items across all the partitions"),(0,i.mdx)("li",{parentName:"ol"},"With the help of collector, client pulls streams from all the nodes and merges them into a single stream"),(0,i.mdx)("li",{parentName:"ol"},"The stream is collected into a list that we can work with. In the example we simply print out the first 100 words")),(0,i.mdx)("p",null,"Finally, we create ",(0,i.mdx)("em",{parentName:"p"},"main")," method that launches the client."),(0,i.mdx)("p",null,(0,i.mdx)("strong",{parentName:"p"},(0,i.mdx)(d.Z,{url:"/examples/core/dataflow/src/main/java/DataflowClientLauncherExample.java",mdxType:"Githublink"},"See full example on GitHub"))),(0,i.mdx)("h3",{id:"testing"},"Testing"),(0,i.mdx)("p",null,"First, launch two dataflow servers. You need to specify nodes' addresses and source files as program arguments.\n",(0,i.mdx)("strong",{parentName:"p"},"Server Launcher 1")," arguments: ",(0,i.mdx)("inlineCode",{parentName:"p"},"9000 words1.txt"),". ",(0,i.mdx)("strong",{parentName:"p"},"Server Launcher 2")," arguments: ",(0,i.mdx)("inlineCode",{parentName:"p"},"9001 words2.txt"),".\nNext, launch dataflow client to post the created task to the servers. You'll need to specify the ports of the partitions\nas program arguments: ",(0,i.mdx)("inlineCode",{parentName:"p"},"9000 9001"),"."),(0,i.mdx)("p",null,"After everything is launched and the task is executed, in the console you will see the list of the first 100 words\ncollected from the two dataflow servers.\nAll the data flows between partitions are represented in sysout and can be transformed into the following graph:"),(0,i.mdx)(o.Z,{chart:"\ngraph TB\n    id5-.->id13\n    subgraph #2\n    id1(SupplierOfId)--\x3eid2(Map)\n    id2--\x3eid3(Sort)\n    id3--\x3eid4(Reduce Simple)\n    id4--\x3eid5(Shard)\n    id5-.->id6(Reduce)\n    id6--\x3eid7(Upload)\n    end\n    id12-.->id6\n    subgraph #1\n    id8(SupplierOfId)--\x3eid9(Map)\n    id9--\x3eid10(Sort)\n    id10--\x3eid11(Reduce Simple)\n    id11--\x3eid12(Shard)\n    id12-.->id13(Reduce)\n    id13--\x3eid14(Upload)\n    end\n",mdxType:"Mermaid"}))}h.isMDXComponent=!0},11748:function(e,t,a){var n={"./locale":89234,"./locale.js":89234};function r(e){var t=i(e);return a(t)}function i(e){if(!a.o(n,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return n[e]}r.keys=function(){return Object.keys(n)},r.resolve=i,e.exports=r,r.id=11748}}]);